{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "import lazypredict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tnrange\n",
    "import itertools\n",
    "from sklearn.impute import KNNImputer\n",
    "import tqdm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from scipy.spatial.distance import cdist\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_district(x):\n",
    "    return x.replace(\"NeukÃ¶lln\",\"Neukölln\").replace('Tempelhof - SchÃ¶neberg','Tempelhof - Schöneberg').replace('Treptow - KÃ¶penick','Treptow - Köpenick').replace('Charlottenburg-Wilm.','Charlottenburg-Wilmersdorf').replace('Ã¶','ö').replace('Ã¤','ä').replace('Ã','ß')\n",
    "\n",
    "def closest_point(point, points):\n",
    "    \"\"\" Find closest point from a list of points. \"\"\"\n",
    "    return points[cdist([point], points).argmin()]\n",
    "\n",
    "def match_value(df, col1, x, col2):\n",
    "    \"\"\" Match value x from col1 row to value in col2. \"\"\"\n",
    "    return df[df[col1] == x][col2].values[0]\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "    \"\"\"\n",
    "    slightly modified version: of http://stackoverflow.com/a/29546836/2901002\n",
    "\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees or in radians)\n",
    "\n",
    "    All (lat, lon) coordinates must have numeric dtypes and be of equal length.\n",
    "\n",
    "    \"\"\"\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def get_training_data(data_files):\n",
    "    df_train = pd.read_csv(data_files['train_airbnb'])\n",
    "    \n",
    "    metro_stations_df = pd.read_csv(data_files['berlin_metro_stations'])[['name','station_category','metro_latitude','metro_longitude']]\n",
    "    bus_stations_df = pd.read_csv(data_files['berlin_bus_stations'])[['name','bus_latitude','bus_longitude']]\n",
    "    tramway_stations_df = pd.read_csv(data_files['berlin_tramway_stations'])[['name','tramway_latitude','tramway_longitude']]\n",
    "    metro_stations_df['point'] = [(x, y) for x,y in zip(metro_stations_df['metro_latitude'], metro_stations_df['metro_longitude'])]\n",
    "    bus_stations_df['point'] = [(x, y) for x,y in zip(bus_stations_df['bus_latitude'], bus_stations_df['bus_longitude'])]\n",
    "    tramway_stations_df['point'] = [(x, y) for x,y in zip(tramway_stations_df['tramway_latitude'], tramway_stations_df['tramway_longitude'])]\n",
    "\n",
    "    df_train['point'] = [(x, y) for x,y in zip(df_train['Latitude'], df_train['Longitude'])]\n",
    "    df_train['closest'] = [closest_point(x, list(metro_stations_df['point'])) for x in df_train['point']]\n",
    "    df_train[['closest_metro_latitude','closest_metro_longitude']] = pd.DataFrame(df_train['closest'].tolist(),index=df_train.index)\n",
    "    df_train['metro_category'] = [match_value(metro_stations_df, 'point', x, 'station_category') for x in df_train['closest']]\n",
    "    df_train['distance_to_closest_metro'] = haversine(df_train['Latitude'], df_train['Longitude'], df_train['closest_metro_latitude'], df_train['closest_metro_longitude'])\n",
    "    df_train = df_train.drop(['point','closest','closest_metro_latitude','closest_metro_longitude'], axis=1)\n",
    "    df_train['point'] = [(x, y) for x,y in zip(df_train['Latitude'], df_train['Longitude'])]\n",
    "    df_train['closest'] = [closest_point(x, list(bus_stations_df['point'])) for x in df_train['point']]\n",
    "    df_train[['closest_bus_latitude','closest_bus_longitude']] = pd.DataFrame(df_train['closest'].tolist(),index=df_train.index)\n",
    "    df_train['distance_to_closest_bus'] = haversine(df_train['Latitude'], df_train['Longitude'], df_train['closest_bus_latitude'], df_train['closest_bus_longitude'])\n",
    "    df_train = df_train.drop(['point','closest','closest_bus_latitude','closest_bus_longitude'], axis=1)\n",
    "    df_train['point'] = [(x, y) for x,y in zip(df_train['Latitude'], df_train['Longitude'])]\n",
    "    df_train['closest'] = [closest_point(x, list(tramway_stations_df['point'])) for x in df_train['point']]\n",
    "    df_train[['closest_tramway_latitude','closest_tramway_longitude']] = pd.DataFrame(df_train['closest'].tolist(),index=df_train.index)\n",
    "    df_train['distance_to_closest_tramway'] = haversine(df_train['Latitude'], df_train['Longitude'], df_train['closest_tramway_latitude'], df_train['closest_tramway_longitude'])\n",
    "    df_train = df_train.drop(['point','closest','closest_tramway_latitude','closest_tramway_longitude'], axis=1)\n",
    "\n",
    "    crimes_df = pd.read_csv(data_files['berlin_crimes'])\n",
    "    crimes_df = crimes_df.groupby(['District','Year']).sum().groupby('District').mean().drop('Code', axis=1)\n",
    "\n",
    "    demographics_df = pd.read_csv(data_files['berlin_demographics'], delimiter=';', encoding='latin-1')\n",
    "    demographics_df['Code Postal'] = demographics_df.apply(lambda x: x['Bezirk']*10000+x['Ortsteil']*10+x['Geschl'], axis=1)\n",
    "    demographics_df = demographics_df[['Code Postal', 'Bez-Name', 'Ortst-Name', 'Staatsangeh','Altersgr', 'Häufigkeit']]\n",
    "    demographics_df = demographics_df.rename(columns = {\"Bez-Name\":\"District\",\"Häufigkeit\": \"Population\", \"Altersgr\":\"Tranche d'âge\",\"Staatsangeh\":\"Origine\"})\n",
    "    number_of_inhabitants_df = demographics_df.groupby(['Code Postal','District','Ortst-Name']).sum()\n",
    "    number_of_germans_df = demographics_df.groupby(['Code Postal','District','Ortst-Name','Origine']).sum().query('Origine==\"D\"').rename(columns = {\"Population\":\"Nb Allemands\"})\n",
    "    number_of_immigrants_df = demographics_df.groupby(['Code Postal','District','Ortst-Name','Origine']).sum().query('Origine==\"A\"').rename(columns = {\"Population\":\"Nb Immigrants\"})\n",
    "    demographics_df = number_of_inhabitants_df.merge(number_of_germans_df, how='inner', on=['Code Postal','District','Ortst-Name']).merge(number_of_immigrants_df, how='inner', on=['Code Postal','District','Ortst-Name'])\n",
    "    demographics_df['Proportion Allemands'] = demographics_df.apply(lambda x: x['Nb Allemands']/x['Population'], axis=1)\n",
    "    demographics_df['Proportion Immigrants'] = demographics_df.apply(lambda x: x['Nb Immigrants']/x['Population'], axis=1)\n",
    "    demographics_df = demographics_df[['Population','Proportion Allemands','Proportion Immigrants']]\n",
    "\n",
    "    extra_data_df = demographics_df.reset_index().merge(crimes_df, how='left', on='District')\n",
    "    for column in extra_data_df.columns:\n",
    "        if column in ['Robbery','Street_robbery', 'Injury', 'Agg_assault', 'Threat', 'Theft', 'Car','From_car', 'Bike', 'Burglary', 'Fire', 'Arson', 'Damage', 'Graffiti','Drugs', 'Local']:\n",
    "            extra_data_df[column] = extra_data_df.apply(lambda x: x[column]/x['Population'], axis=1)\n",
    "    \n",
    "    extra_data_df = extra_data_df.drop_duplicates(['Ortst-Name'])\n",
    "\n",
    "    df_train['neighbourhood'] = df_train['neighbourhood'].apply(lambda x:cast_district(x))\n",
    "    df_train['Neighborhood Group'] = df_train['Neighborhood Group'].apply(lambda x:cast_district(x))\n",
    "    df_train = df_train.merge(extra_data_df, how='left', left_on='neighbourhood', right_on='Ortst-Name')\n",
    "\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train_airbnb\": \"../DATA/train_airbnb_berlin.xls\",\n",
    "    \"berlin_crimes\": \"../DATA/extra_datasets/Berlin_crimes.csv\",\n",
    "    \"berlin_demographics\": \"../DATA/extra_datasets/Berlin_demographics.csv\",\n",
    "    \"berlin_bus_stations\": \"../DATA/extra_datasets/Berlin_bus_stations.csv\",\n",
    "    \"berlin_tramway_stations\": \"../DATA/extra_datasets/Berlin_tramway_stations.csv\",\n",
    "    \"berlin_metro_stations\": \"../DATA/extra_datasets/Berlin_metro_stations.csv\",\n",
    "}\n",
    "\n",
    "df_train = get_training_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subplot_analysis():\n",
    "    plt.subplot(221)\n",
    "    df_train.boxplot(column='Price')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    df_train.boxplot(column='Square Feet')\n",
    "\n",
    "    plt.subplot(223)\n",
    "    df_train.boxplot(column='Value Rating')\n",
    "\n",
    "    plt.subplot(224)\n",
    "    df_train.boxplot(column='Accuracy Rating')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_nans(df: pd.DataFrame) -> list:\n",
    "    nan_percentage = pd.DataFrame(columns=['Feature Name', 'Percentage of NaNs'])\n",
    "    for idx, feature in enumerate(df.columns):\n",
    "        notnans = df_train[feature].notna().value_counts()\n",
    "        percentage = 0\n",
    "        if False in notnans:\n",
    "            percentage = int(10000*notnans[False]/len(df_train))/100\n",
    "\n",
    "        nan_percentage.loc[idx] = [feature, percentage]\n",
    "    return nan_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_percentage_analysis():\n",
    "    nan_percentage = percentage_of_nans(df_train)\n",
    "    df = nan_percentage[nan_percentage['Percentage of NaNs'] >= 18]\n",
    "    display(df.sort_values(by=['Percentage of NaNs'], ascending=False).reset_index().drop(['index'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Percentage of NaNs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Square Feet</td>\n",
       "      <td>98.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metro_category</td>\n",
       "      <td>67.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Host Response Time</td>\n",
       "      <td>45.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Host Response Rate</td>\n",
       "      <td>45.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Checkin Rating</td>\n",
       "      <td>18.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accuracy Rating</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Location Rating</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Value Rating</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cleanliness Rating</td>\n",
       "      <td>18.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Communication Rating</td>\n",
       "      <td>18.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Overall Rating</td>\n",
       "      <td>18.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature Name  Percentage of NaNs\n",
       "0            Square Feet               98.06\n",
       "1         metro_category               67.02\n",
       "2     Host Response Time               45.08\n",
       "3     Host Response Rate               45.08\n",
       "4         Checkin Rating               18.94\n",
       "5        Accuracy Rating               18.93\n",
       "6        Location Rating               18.93\n",
       "7           Value Rating               18.93\n",
       "8     Cleanliness Rating               18.92\n",
       "9   Communication Rating               18.92\n",
       "10        Overall Rating               18.87"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nan_percentage_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns. str.lower().str.replace(' ','_')         \n",
    "\n",
    "    # Converting to datetime\n",
    "    df.host_since = pd.to_datetime(df.host_since)               \n",
    "\n",
    "    cols_to_drop = ['listing_name', 'host_id', 'host_name', 'city', 'country_code', 'country', \n",
    "                    'first_review', 'last_review', 'neighbourhood', 'business_travel_ready',  'postal_code', 'district', 'ortst-name', 'code_postal']\n",
    "\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    df.set_index('listing_id', inplace=True)\n",
    "\n",
    "    df.drop(['square_feet'], axis=1, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].replace('*', np.nan)\n",
    "\n",
    "    df = df.dropna(subset=['price'], how='all')\n",
    "    df = df.dropna(subset=['overall_rating', 'accuracy_rating','cleanliness_rating','checkin_rating',\n",
    "                            'communication_rating','location_rating','value_rating'], how='all')\n",
    "    \n",
    "    numerical_features = ['accomodates','latitude',\n",
    "          'longitude','bathrooms','bedrooms','beds','guests_included','min_nights','reviews','overall_rating','accuracy_rating',\n",
    "          'cleanliness_rating','checkin_rating', 'communication_rating','location_rating','value_rating']\n",
    "\n",
    "    label_encoded = ['host_response_time', 'is_superhost', 'is_exact_location', 'instant_bookable']\n",
    "\n",
    "    categorical_variables = ['room_type', 'property_type','neighborhood_group'] \n",
    "    for i in numerical_features:\n",
    "        df[i]=pd.to_numeric(df[i], downcast=\"float\")\n",
    "\n",
    "    #Replacing the null values\n",
    "\n",
    "    df['host_response_rate'] = df['host_response_rate'].map(lambda x: str(x), na_action='ignore').map(lambda x : int(x[:-1]), na_action='ignore') \n",
    "\n",
    "    for cat_var in categorical_variables:\n",
    "        dummie = pd.get_dummies(df[cat_var])\n",
    "        df = pd.concat([df, dummie], axis=1)\n",
    "\n",
    "    df.drop(categorical_variables, axis=1, inplace=True)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    for i in label_encoded:\n",
    "        df[i] = le.fit_transform(df[i].astype(str))\n",
    "    \n",
    "    X = df.drop('price', axis = 1)\n",
    "\n",
    "    # Output/Dependent variable\n",
    "\n",
    "    y = df['price']\n",
    "    return X, y\n",
    "\n",
    "def median_imputer(df: pd.DataFrame):\n",
    "    numerical_features = ['accomodates','latitude',\n",
    "        'longitude','bathrooms','bedrooms','beds','guests_included','min_nights','reviews','overall_rating','accuracy_rating',\n",
    "        'cleanliness_rating','checkin_rating', 'communication_rating','location_rating','value_rating' ]\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    if 'host_since' in df.columns:\n",
    "        # Calculating the number of days    \n",
    "        df['host_days_active'] = (datetime(2019, 7, 21) - df.host_since).astype('timedelta64[D]').copy()\n",
    "\n",
    "        # Replacing null values with the median\n",
    "        df['host_days_active'] = df.host_days_active.fillna(df.host_days_active.median()).copy()\n",
    "\n",
    "        df['host_days_active'] = (datetime(2019, 7, 21) - df.host_since).astype('timedelta64[D]').copy()\n",
    "        df.drop('host_since', axis=1, inplace=True)\n",
    "\n",
    "    for col in numerical_features:\n",
    "        if col not in df.columns:continue\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    df = df.fillna(0).copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_clf_scaler_cv(clf, X, y, clf_params, pipeline_params={}, n_features=50):\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    rmse_list = []\n",
    "    r2_list = []\n",
    "    X = median_imputer(X)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "        pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=n_features)),\n",
    "        ('svr', clf(**clf_params))], **pipeline_params)\n",
    "        \n",
    "        pipe.fit(X_train,y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        rmse = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(pipe.score(X_test, y_test))\n",
    "    return np.array(rmse_list).mean(), np.array(r2_list).mean()\n",
    "\n",
    "def fit_clf_scaler(clf, X, y, clf_params, pipeline_params={}, n_features=50):\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    pipe = Pipeline([('median_imputer', FunctionTransformer(median_imputer)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=n_features)),\n",
    "    ('svr', clf(**clf_params))], **pipeline_params)\n",
    "    \n",
    "    pipe.fit(X,y)\n",
    "    return pipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pre_process_raw(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_analysis():\n",
    "    plt.hist(y_train,bins=100, label='train')\n",
    "    plt.hist(y_test, bins=100,label='test')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x')\n",
    "    plt.show()\n",
    "\n",
    "    f = Fitter(y.values,\n",
    "            distributions=['gamma',\n",
    "                            'lognorm',\n",
    "                            \"beta\",\n",
    "                            \"burr\",\n",
    "                            \"norm\"])\n",
    "    f.fit()\n",
    "    f.summary()\n",
    "\n",
    "    f_train = Fitter(y_train.values, distributions=['burr'])\n",
    "    f_train.fit()\n",
    "\n",
    "    display(f_train.get_best())\n",
    "\n",
    "    f_test = Fitter(y_test.values, distributions=['burr'])\n",
    "    f_test.fit()\n",
    "    display(f_test.get_best())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 5 distributions: 100%|███████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.56it/s]\n",
      "Fitting 1 distributions: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'burr': {'c': 2.3918847639235943,\n",
       "  'd': 2.6672527926210923,\n",
       "  'loc': -0.0923998227354602,\n",
       "  'scale': 28.50641342786434}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 1 distributions: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'burr': {'c': 2.5829527482788075,\n",
       "  'd': 1.8337441549196827,\n",
       "  'loc': -0.10671963192032685,\n",
       "  'scale': 35.77353089594571}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_train_test_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pca_analysis():\n",
    "    pipe = Pipeline([('median_imputer', FunctionTransformer(median_imputer)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA())])\n",
    "\n",
    "    pipe.fit(X_train)\n",
    "    explained_variance = pipe['pca'].explained_variance_ratio_\n",
    "    acc_sum = np.cumsum(explained_variance) \n",
    "\n",
    "    plt.title('Cumulative explained variance')\n",
    "    plt.plot(acc_sum)\n",
    "    plt.grid()\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.plot(50, 0.99132,'ro') \n",
    "    plt.show()\n",
    "\n",
    "    print('Explained variance with 51 features: ', acc_sum[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brido\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0811d5284ead>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_pca_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-c0f1dc1a8feb>\u001b[0m in \u001b[0;36mmake_pca_analysis\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     ('pca', PCA())])\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mexplained_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pca'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0macc_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexplained_variance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         if (self.check_inverse and not (self.func is None or\n\u001b[0;32m    134\u001b[0m                                         self.inverse_func is None)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36m_check_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "make_pca_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_collinearity_heatmap(df, figsize=(11,9)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a heatmap of correlations between features in the df. A figure size can optionally be set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the style of the visualization\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Create a covariance matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask the size of our covariance matrix\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmax=corr[corr != 1.0].max().max())\n",
    "    f.savefig(\"matrix.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward selection + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(clf, params):\n",
    "\tr2 = [] \n",
    "\trmse = []\n",
    "\tfeatures = []\n",
    "\tn_features = []\n",
    "\n",
    "\tfor k in range(1,len(X.columns) + 1):\n",
    "\t\tr2_tmp = []\n",
    "\t\trmse_tmp = []\n",
    "\t\tfor new_feat in X_train.columns:\n",
    "\t\t\tif new_feat in features: continue\n",
    "\t\t\tnew_features = features.copy()\n",
    "\t\t\tnew_features.append(new_feat)\n",
    "\t\t\tpipe = fit_clf_scaler(clf, X_train[new_features],y_train, params, {}, n_features=len(new_features))   \n",
    "\t\t\tr_squared = pipe.score(X_test[new_features],y_test)\n",
    "\t\t\ty_pred = pipe.predict(X_test[new_features])\n",
    "\t\t\trmse_val = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "\t\t\tr2_tmp.append((r_squared, new_feat))                 \n",
    "\t\t\trmse_tmp.append(rmse_val)\n",
    "\t\tr2.append(sorted(r2_tmp, key=lambda x: x[0])[-1][0])\t\n",
    "\t\trmse.append(sorted(rmse_tmp)[-1])\n",
    "\t\tnew_feat = sorted(r2_tmp, key=lambda x: x[0])[-1][1]\n",
    "\t\tfeatures.append(new_feat)\n",
    "\t\tn_features.append(len(features))   \n",
    "\n",
    "\tdf = pd.DataFrame({'n_features': n_features,'R2': r2, 'RMSE':rmse ,'features':features})\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_selection_analysis():\n",
    "    df = get_feature_importance(linear_model.LinearRegression, {})\n",
    "    plt.title('Cross-validated subset selection - Linear Regression')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.ylabel('R squared')\n",
    "    plt.grid()\n",
    "    plt.plot(df['n_features'], df['R2'])\n",
    "    plt.show()\n",
    "\n",
    "    plt.title('Cross-validated subset selection - Linear Regression')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.grid()\n",
    "    plt.plot(df['n_features'], df['RMSE'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_analysis():\n",
    "    rmse = []\n",
    "    max_depth = []\n",
    "    for k in range(1, 30):\n",
    "        rmse_val = fit_clf_scaler_cv(DecisionTreeRegressor, X_train,y_train, {\"max_depth\": k}, {\"verbose\": 0}, n_features=25) \n",
    "        rmse.append(rmse_val)\t\n",
    "        max_depth.append(k)\n",
    "\n",
    "    df = pd.DataFrame({'RMSE': rmse,'max_depth':max_depth})\n",
    "    plt.title('Influence of the max depth - Decision Tree Regression - 5 fold CV')\n",
    "    plt.xlabel('Max depth')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.grid()\n",
    "    plt.plot(df['max_depth'], df['RMSE'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.29524622401338807\n",
      "rmse:  40.53773630460914\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'max_depth': 4, 'min_samples_split': 2}\n",
    "rmse, r_squared = fit_clf_scaler_cv(DecisionTreeRegressor, X_train, y_train, clf_params)\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_smv():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        parameters = {\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'C': trial.suggest_float('C', 1e-3, 1e3),\n",
    "            'epsilon': trial.suggest_float('epsilon', 1e-3, 1)\n",
    "        }\n",
    "\n",
    "        clf = svm.SVR\n",
    "        return -fit_clf_scaler(clf, X_train, y_train, parameters)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.2972519443161502\n",
      "rmse:  40.55568432031913\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'kernel': 'rbf'}#, 'C': 595.6756199722245, 'epsilon': 0.8771538699650302}\n",
    "rmse, r_squared = fit_clf_scaler_cv(svm.SVR, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params = {'kernel': 'rbf'}#, 'C': 595.6756199722245, 'epsilon': 0.8771538699650302}\n",
    "pipe = fit_clf_scaler(svm.SVR, X_train, y_train, clf_params, {\"verbose\": 1})\n",
    "r_squared = pipe.score(X_test,y_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "rmse = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_adaboost():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        parameters = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1)\n",
    "        }\n",
    "\n",
    "        clf = AdaBoostRegressor\n",
    "        return -fit_clf_scaler(clf, X_train, y_train, parameters, n_features=5)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  -0.6497676215866125\n",
      "rmse:  61.37468806386445\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'n_estimators': 119, 'learning_rate': 0.9617041908836014}\n",
    "rmse, r_squared = fit_clf_scaler_cv(AdaBoostRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_knn():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        trial_suggestion = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 200),\n",
    "            'leaf_size': trial.suggest_int('leaf_size', 10, 50),\n",
    "        }\n",
    "\n",
    "        clf_params = {\n",
    "            'n_neighbors': trial_suggestion['n_neighbors'],\n",
    "            'leaf_size': trial_suggestion['leaf_size'],\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        imputer_params = {\n",
    "            \"n_neighbors\": 3\n",
    "        }\n",
    "\n",
    "        clf = KNeighborsRegressor\n",
    "        return fit_clf_scaler_cv(clf, X_train, y_train, clf_params, imputer_params, n_features=28)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=30, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.37091845519248884\n",
      "rmse:  38.36226989167497\n"
     ]
    }
   ],
   "source": [
    "clf_params =  {'n_neighbors': 84, 'leaf_size': 26}\n",
    "rmse, r_squared = fit_clf_scaler_cv(KNeighborsRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gradient_boost():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        trial_suggestion = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors',  2, 4),\n",
    "            'n_features': trial.suggest_int('n_features', 10, 54)\n",
    "        }\n",
    "\n",
    "        clf_params = {\n",
    "            'n_estimators': trial_suggestion['n_estimators'],\n",
    "            'learning_rate': trial_suggestion['learning_rate'],\n",
    "            'max_depth': trial_suggestion['max_depth'],\n",
    "        }\n",
    "        imputer_params = {\n",
    "            \"n_neighbors\": trial_suggestion['n_neighbors']\n",
    "        }\n",
    "\n",
    "        clf = GradientBoostingRegressor\n",
    "        return fit_clf_scaler_cv(clf, X_train, y_train, clf_params, imputer_params, n_features=trial_suggestion['n_features'])\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.44862956047248365\n",
      "rmse:  35.926325865221045\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'n_estimators': 178, 'learning_rate': 0.15253399946567545, 'max_depth': 2} \n",
    "rmse, r_squared = fit_clf_scaler_cv(GradientBoostingRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 4) Processing median_imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 4) Processing pca, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing svr, total=  16.5s\n",
      "r_squared:  0.37931461886713536\n",
      "rmse:  33.682215060732275\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'n_estimators': 178, 'learning_rate': 0.15253399946567545, 'max_depth': 2} \n",
    "pipe = fit_clf_scaler(GradientBoostingRegressor, X_train, y_train, clf_params, {\"verbose\": 1})\n",
    "r_squared = pipe.score(X_test,y_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "rmse = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "def optimize_mlp():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        trial_suggestions = {\n",
    "            'first_layer': trial.suggest_int('first_layer', 1, 100),\n",
    "            'second_layer': trial.suggest_int('second_layer', 1, 100),\n",
    "            'activation': trial.suggest_categorical('activation', ['relu', 'logistic', 'tanh', 'relu'])\n",
    "        }\n",
    "\n",
    "        clf = MLPRegressor \n",
    "        clf_params = {\n",
    "            'hidden_layer_sizes': (trial_suggestions['first_layer'], trial_suggestions['second_layer']),#, trial_suggestions['third_layer']),\n",
    "            'activation': trial_suggestions['activation'],\n",
    "            'max_iter': 200,\n",
    "            'learning_rate': 'adaptive'\n",
    "        }\n",
    "        rmse, r_squared = fit_clf_scaler_cv(clf, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "        return rmse\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.44564953583781264\n",
      "rmse:  36.003689845910586\n"
     ]
    }
   ],
   "source": [
    "clf_params = {\n",
    "    \"hidden_layer_sizes\": (38, 4),\n",
    "    \"activation\": 'relu'\n",
    "}\n",
    "rmse, r_squared = fit_clf_scaler_cv(sklearn.neural_network.MLPRegressor , X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 4) Processing median_imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 4) Processing pca, total=   0.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing svr, total=  24.8s\n",
      "r_squared:  0.36926060400295857\n",
      "rmse:  33.95391562520712\n"
     ]
    }
   ],
   "source": [
    "clf_params = {\n",
    "    \"hidden_layer_sizes\": (38, 4),\n",
    "    \"activation\": 'relu'\n",
    "}\n",
    "pipe = fit_clf_scaler(sklearn.neural_network.MLPRegressor, X_train, y_train, clf_params, {\"verbose\": 1})\n",
    "r_squared = pipe.score(X_test,y_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "rmse = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.45876928833930364\n",
      "rmse:  35.59095578695318\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "clf_params = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"n_estimators\":6000,\n",
    "    \"max_depth\":4,\n",
    "    \"min_child_weight\":0,\n",
    "    \"gamma\":0.6,\n",
    "    \"subsample\":0.7,\n",
    "    \"colsample_bytree\":0.7,\n",
    "    \"objective\":'reg:squarederror',\n",
    "    \"nthread\":-1,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"seed\":27,\n",
    "    \"reg_alpha\":0.00006,\n",
    "    \"random_state\":42\n",
    "}\n",
    "rmse, r_squared = fit_clf_scaler_cv(XGBRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.38844212882150575\n",
      "rmse:  33.433640341309186\n"
     ]
    }
   ],
   "source": [
    "clf_params = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"n_estimators\":6000,\n",
    "    \"max_depth\":4,\n",
    "    \"min_child_weight\":0,\n",
    "    \"gamma\":0.6,\n",
    "    \"subsample\":0.7,\n",
    "    \"colsample_bytree\":0.7,\n",
    "    \"objective\":'reg:squarederror',\n",
    "    \"nthread\":-1,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"seed\":27,\n",
    "    \"reg_alpha\":0.00006,\n",
    "    \"random_state\":42\n",
    "}\n",
    "\n",
    "pipe = fit_clf_scaler(XGBRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "r_squared = pipe.score(X_test,y_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "rmse = mean_squared_error(y_pred, y_test)**(1/2)\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_random_forest():\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "        trial_suggestion = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors',  2, 4),\n",
    "        }\n",
    "\n",
    "        clf_params = {\n",
    "            \"n_estimators\": trial_suggestion['n_estimators'],\n",
    "            \"criterion\": \"squared_error\",\n",
    "\n",
    "        }\n",
    "        imputer_params = {\n",
    "            \"n_neighbors\": trial_suggestion['n_neighbors']\n",
    "        }\n",
    "\n",
    "        clf = GradientBoostingRegressor\n",
    "        return fit_clf_scaler_cv(clf, X_train, y_train, clf_params, imputer_params, n_features=28)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared:  0.399921567827145\n",
      "rmse:  37.46812066344361\n"
     ]
    }
   ],
   "source": [
    "clf_params = {'n_estimators': 134, 'max_depth': 5}\n",
    "rmse, r_squared = fit_clf_scaler_cv(RandomForestRegressor, X_train, y_train, clf_params, {\"verbose\": 0})\n",
    "\n",
    "print('r_squared: ', r_squared)\n",
    "print('rmse: ', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
